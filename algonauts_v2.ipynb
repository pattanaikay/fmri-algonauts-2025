{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c0d411",
   "metadata": {},
   "source": [
    "v2 of Algonauts Projects with extended procedures and approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df17cda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "CUDA Device 0:\n",
      "  Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "  Compute Capability: 8.9\n",
      "  Total Memory: 6.00 GB\n",
      "\n",
      "Current CUDA device: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking GPU availability and properties using PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA is available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the number of CUDA devices\n",
    "    n_cuda_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices: {n_cuda_devices}\")\n",
    "    \n",
    "    # Print information for each CUDA device\n",
    "    for i in range(n_cuda_devices):\n",
    "        device_props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"\\nCUDA Device {i}:\")\n",
    "        print(f\"  Name: {device_props.name}\")\n",
    "        print(f\"  Compute Capability: {device_props.major}.{device_props.minor}\")\n",
    "        print(f\"  Total Memory: {device_props.total_memory / 1024**3:.2f} GB\")\n",
    "        \n",
    "    # Get current device information\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"\\nCurrent CUDA device: {current_device}\")\n",
    "else:\n",
    "    print(\"No CUDA devices found. PyTorch will run on CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d7e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "--------------------------------------------------\n",
      "Python Version: 3.11.0\n",
      "PyTorch Version: 2.7.1+cu118\n",
      "CUDA Available: True\n",
      "CUDA Version: 11.8\n",
      "\n",
      "GPU Information:\n",
      "--------------------------------------------------\n",
      "Sat Sep 20 10:58:18 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.29                 Driver Version: 581.29         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   40C    P8              5W /   50W |       0MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           18852      C   ...s\\Python\\Python311\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking system configuration\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def check_nvidia_gpu():\n",
    "    try:\n",
    "        # Try to get GPU info using nvidia-smi\n",
    "        output = subprocess.check_output(['nvidia-smi'], stderr=subprocess.STDOUT)\n",
    "        return output.decode('utf-8')\n",
    "    except:\n",
    "        return \"No NVIDIA GPU detected or nvidia-smi not found\"\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(\"\\nGPU Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(check_nvidia_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18af2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries (the most fun part of all the code)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import librosa\n",
    "import ast\n",
    "import string\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import pearsonr\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, Dropdown, Button\n",
    "from IPython.display import Video, display, clear_output\n",
    "from moviepy.editor import VideoFileClip\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchvision.transforms import Compose, Lambda, CenterCrop\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78332882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (algonauts)",
   "language": "python",
   "name": "algonauts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
